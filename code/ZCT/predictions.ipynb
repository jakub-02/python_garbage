{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-05T17:10:07.722867Z",
     "start_time": "2025-04-05T16:59:41.613679Z"
    }
   },
   "source": [
    "# trenovanie a ukladanie modelov\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import os\n",
    "\n",
    "# Stock tickers\n",
    "tickers = [\n",
    "    'NVDA', 'TSLA', 'INTC', 'F', 'AAPL', 'MSFT', 'AMZN',\n",
    "    'GOOGL', 'META', 'BRK-B', 'JPM', 'V', 'JNJ', 'WMT',\n",
    "    'PG', 'XOM', 'NKE', 'CVS', 'PM', 'NEM'\n",
    "]\n",
    "\n",
    "start_date = '2020-04-01'\n",
    "end_date = '2025-04-01'\n",
    "time_steps = 10\n",
    "\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "def create_lstm_data(data, time_steps=1):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        x.append(data[i:(i + time_steps), 0])\n",
    "        y.append(data[i + time_steps, 0])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"\\nProcessing {ticker}...\")\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    if data.empty:\n",
    "        print(f\"No data for {ticker}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    close_prices = data['Close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    close_prices_scaled = scaler.fit_transform(close_prices)\n",
    "\n",
    "    x, y = create_lstm_data(close_prices_scaled, time_steps)\n",
    "    x = np.reshape(x, (x.shape[0], x.shape[1], 1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(x.shape[1], 1)))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(x, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # ✅ Save model\n",
    "    model.save(f\"{model_dir}/{ticker}.h5\")\n",
    "\n",
    "    # ✅ Save scaler\n",
    "    import joblib\n",
    "    joblib.dump(scaler, f\"{model_dir}/{ticker}_scaler.gz\")\n",
    "\n",
    "    print(f\"Saved model and scaler for {ticker}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for NVDA\n",
      "\n",
      "Processing TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for TSLA\n",
      "\n",
      "Processing INTC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for INTC\n",
      "\n",
      "Processing F...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for F\n",
      "\n",
      "Processing AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for AAPL\n",
      "\n",
      "Processing MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for MSFT\n",
      "\n",
      "Processing AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for AMZN\n",
      "\n",
      "Processing GOOGL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for GOOGL\n",
      "\n",
      "Processing META...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for META\n",
      "\n",
      "Processing BRK-B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for BRK-B\n",
      "\n",
      "Processing JPM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for JPM\n",
      "\n",
      "Processing V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for V\n",
      "\n",
      "Processing JNJ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for JNJ\n",
      "\n",
      "Processing WMT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for WMT\n",
      "\n",
      "Processing PG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for PG\n",
      "\n",
      "Processing XOM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for XOM\n",
      "\n",
      "Processing NKE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for NKE\n",
      "\n",
      "Processing CVS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for CVS\n",
      "\n",
      "Processing PM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler for PM\n",
      "\n",
      "Processing NEM...\n",
      "Saved model and scaler for NEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\newConda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T18:07:15.036065Z",
     "start_time": "2025-04-05T18:07:13.031819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lokalny test modelu\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "ticker = 'TSLA'\n",
    "\n",
    "def predict_next_days(ticker, days=10, time_steps=10, end_date='2025-04-05'):\n",
    "    model = load_model(f\"models/{ticker}.h5\")\n",
    "    scaler = joblib.load(f\"models/{ticker}_scaler.gz\")\n",
    "    start_date = '2020-04-01'\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    close_prices = data['Close'].values.reshape(-1, 1)\n",
    "    close_prices_scaled = scaler.transform(close_prices)\n",
    "\n",
    "    last_data = close_prices_scaled[-time_steps:]\n",
    "    last_data = np.reshape(last_data, (1, time_steps, 1))\n",
    "\n",
    "    future_predictions = []\n",
    "    for _ in range(days):\n",
    "        pred = model.predict(last_data, verbose=0)\n",
    "        future_predictions.append(pred[0][0])\n",
    "        last_data = np.append(last_data[:, 1:, :], pred.reshape(1, 1, 1), axis=1)\n",
    "\n",
    "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
    "    return future_predictions\n",
    "\n",
    "print(predict_next_days(ticker, 5, 10, '2025-04-05'))\n"
   ],
   "id": "fb6093ac90ec6f61",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 38 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024D3A31EAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 38 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024D3A31EAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254.91391]\n",
      " [250.02374]\n",
      " [247.0321 ]\n",
      " [244.5758 ]\n",
      " [242.4207 ]]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:22:19.380278Z",
     "start_time": "2025-04-05T19:20:00.780946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prevod .h5 modelov na tensorflow, vhodne pre vertex ai\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "for ticker in tickers:\n",
    "    model = tf.keras.models.load_model(f\"models/{ticker}.h5\")\n",
    "    model.save(f\"models/{ticker}c\", save_format='tf')\n"
   ],
   "id": "1160f34d4201f640",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/NVDAc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/NVDAc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/TSLAc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/TSLAc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/INTCc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/INTCc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Fc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Fc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/AAPLc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/AAPLc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/MSFTc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/MSFTc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/AMZNc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/AMZNc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GOOGLc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GOOGLc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/METAc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/METAc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/BRK-Bc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/BRK-Bc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/JPMc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/JPMc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Vc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Vc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/JNJc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/JNJc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/WMTc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/WMTc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/PGc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/PGc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/XOMc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/XOMc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/NKEc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/NKEc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CVSc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CVSc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/PMc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/PMc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/NEMc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/NEMc\\assets\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T17:09:42.221174Z",
     "start_time": "2025-04-07T17:09:37.085760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inicializacia credentials pre vertex ai a storage\n",
    "\n",
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"prefab-shape-455916-i7-be937e48d8e1.json\"\n",
    "\n",
    "aiplatform.init(\n",
    "    project=\"4204132242382913536\",\n",
    "    location=\"europe-central2\"\n",
    ")\n",
    "\n",
    "endpoint = aiplatform.Endpoint(\"4204132242382913536\")\n",
    "\n",
    "import google.auth\n",
    "creds, project = google.auth.default()\n",
    "print(\"Authenticated project:\", project)\n",
    "print(\"Credentials type:\", type(creds))"
   ],
   "id": "9381b05f13bfef42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated project: prefab-shape-455916-i7\n",
      "Credentials type: <class 'google.oauth2.service_account.Credentials'>\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T17:14:43.121391Z",
     "start_time": "2025-04-07T17:14:41.534849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# predickia modelu z endpointu na vertex ai\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import joblib\n",
    "import io\n",
    "\n",
    "def load_scaler_from_gcs(bucket_name, blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    scaler_bytes = blob.download_as_bytes()\n",
    "    scaler = joblib.load(io.BytesIO(scaler_bytes))\n",
    "    return scaler\n",
    "\n",
    "def predict_next_days_vertexai(\n",
    "        ticker, endpoint_id, project, location, days=5, time_steps=10, end_date='2025-04-05'\n",
    "):\n",
    "    # Initialize Vertex AI\n",
    "    aiplatform.init(project=project, location=location)\n",
    "    endpoint = aiplatform.Endpoint(endpoint_id)\n",
    "\n",
    "    # Load scaler from GCS\n",
    "    scaler = load_scaler_from_gcs(\"stock-prediction-zct\", f\"{ticker}_scaler.gz\")\n",
    "\n",
    "    # Download stock data\n",
    "    start_date = '2020-04-01'\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    close_prices = data['Close'].values.reshape(-1, 1)\n",
    "    close_prices_scaled = scaler.transform(close_prices)\n",
    "\n",
    "    # Get the last time_steps data, reshape to (1, time_steps, 1)\n",
    "    last_data = close_prices_scaled[-time_steps:]\n",
    "    print(last_data)\n",
    "    last_data = np.reshape(last_data, (1, time_steps, 1))\n",
    "    print(last_data)\n",
    "\n",
    "    future_predictions = []\n",
    "    for _ in range(days):\n",
    "        response = endpoint.predict(instances=last_data.tolist())\n",
    "        pred = response.predictions[0][0]\n",
    "        future_predictions.append(pred)\n",
    "\n",
    "        last_data = np.append(last_data[:, 1:, :], np.array(pred).reshape(1, 1, 1), axis=1)\n",
    "\n",
    "    print(future_predictions)\n",
    "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
    "    print(future_predictions)\n",
    "    return future_predictions\n",
    "\n",
    "\n",
    "preds = predict_next_days_vertexai(\n",
    "    ticker=\"AAPL\",\n",
    "    endpoint_id=\"4204132242382913536\",\n",
    "    project=\"prefab-shape-455916-i7\",\n",
    "    location=\"europe-central2\",\n",
    "    days=20\n",
    ")\n",
    "\n",
    "#AAPL - 4204132242382913536\n",
    "#NVDA - 8849595258015580160\n",
    "\n",
    "print(preds)"
   ],
   "id": "f8b71ce3b93e5dd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81023027]\n",
      " [0.8253098 ]\n",
      " [0.81422485]\n",
      " [0.82580915]\n",
      " [0.79609945]\n",
      " [0.81722081]\n",
      " [0.82251361]\n",
      " [0.82600885]\n",
      " [0.72264928]\n",
      " [0.64869975]]\n",
      "[[[0.81023027]\n",
      "  [0.8253098 ]\n",
      "  [0.81422485]\n",
      "  [0.82580915]\n",
      "  [0.79609945]\n",
      "  [0.81722081]\n",
      "  [0.82251361]\n",
      "  [0.82600885]\n",
      "  [0.72264928]\n",
      "  [0.64869975]]]\n",
      "[0.74511826, 0.722068, 0.706082523, 0.693850577, 0.685101, 0.676949263, 0.671317875, 0.667188048, 0.664371848, 0.65790391, 0.648788, 0.644508779, 0.639706731, 0.634662151, 0.629504204, 0.624349773, 0.619193196, 0.61411792, 0.609173, 0.604409337]\n",
      "[[207.68990335]\n",
      " [203.07358846]\n",
      " [199.87214972]\n",
      " [197.42243703]\n",
      " [195.67014432]\n",
      " [194.03758205]\n",
      " [192.90977437]\n",
      " [192.08268687]\n",
      " [191.51868169]\n",
      " [190.22333672]\n",
      " [188.39767787]\n",
      " [187.54067099]\n",
      " [186.57895664]\n",
      " [185.56867   ]\n",
      " [184.53567916]\n",
      " [183.50339247]\n",
      " [182.470676  ]\n",
      " [181.45424182]\n",
      " [180.46391426]\n",
      " [179.50988734]]\n",
      "[[207.68990335]\n",
      " [203.07358846]\n",
      " [199.87214972]\n",
      " [197.42243703]\n",
      " [195.67014432]\n",
      " [194.03758205]\n",
      " [192.90977437]\n",
      " [192.08268687]\n",
      " [191.51868169]\n",
      " [190.22333672]\n",
      " [188.39767787]\n",
      " [187.54067099]\n",
      " [186.57895664]\n",
      " [185.56867   ]\n",
      " [184.53567916]\n",
      " [183.50339247]\n",
      " [182.470676  ]\n",
      " [181.45424182]\n",
      " [180.46391426]\n",
      " [179.50988734]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "349e82a3d6a1d52b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
