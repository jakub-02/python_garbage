{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision - Week_04 - Textures"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T08:26:02.301213Z",
     "start_time": "2024-10-31T08:26:01.436042Z"
    }
   },
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.color import label2rgb\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage import color, io, morphology, filters\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.segmentation import find_boundaries, mark_boundaries"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The surface of many objects has a characteristic pattern, a so-called texture. Textures can have different visual properties and we intuitively evaluate them as \"soft\", \"rough\", \"regular\", \"expressive\", and so on. When recognizing textures (segmentation based on information), it is not possible to assess individual points of the image, as we did in the case of segmentation based on brightness or colors. It is done by putting the body of the image in relation with its surroundings. Using texture information, it is possible to segment objects that may not be distinguishable based on other criteria."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T08:26:05.416607Z",
     "start_time": "2024-10-31T08:26:04.497600Z"
    }
   },
   "source": [
    "img = io.imread('example files/jaguar.gif')\n",
    "img = (color.rgb2gray(img[..., 0:3])*255).astype(np.uint8)\n",
    "plt.figure(figsize= (20, 20))\n",
    "plt.title('3 RGB kanÃ¡ly')\n",
    "plt.imshow(img, cmap=\"gray\")"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/home/jakubbaransky/DataspellProjects/compVisionZS/example files/jaguar.gif'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m img \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexample files/jaguar.gif\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m img \u001B[38;5;241m=\u001B[39m (color\u001B[38;5;241m.\u001B[39mrgb2gray(img[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m3\u001B[39m])\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m255\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8)\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m20\u001B[39m))\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/skimage/io/_io.py:60\u001B[0m, in \u001B[0;36mimread\u001B[0;34m(fname, as_gray, plugin, **plugin_args)\u001B[0m\n\u001B[1;32m     57\u001B[0m         plugin \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtifffile\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m file_or_url_context(fname) \u001B[38;5;28;01mas\u001B[39;00m fname:\n\u001B[0;32m---> 60\u001B[0m     img \u001B[38;5;241m=\u001B[39m call_plugin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimread\u001B[39m\u001B[38;5;124m'\u001B[39m, fname, plugin\u001B[38;5;241m=\u001B[39mplugin, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mplugin_args)\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(img, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/skimage/io/manage_plugins.py:217\u001B[0m, in \u001B[0;36mcall_plugin\u001B[0;34m(kind, *args, **kwargs)\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m:\n\u001B[1;32m    215\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCould not find the plugin \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mplugin\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkind\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 217\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/skimage/io/_plugins/imageio_plugin.py:11\u001B[0m, in \u001B[0;36mimread\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(imageio_imread)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimread\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 11\u001B[0m     out \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(imageio_imread(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m out\u001B[38;5;241m.\u001B[39mflags[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWRITEABLE\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m     13\u001B[0m         out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mcopy()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/imageio/v3.py:53\u001B[0m, in \u001B[0;36mimread\u001B[0;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m     call_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m index\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m imopen(uri, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mplugin_kwargs) \u001B[38;5;28;01mas\u001B[39;00m img_file:\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray(img_file\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs))\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/imageio/core/imopen.py:113\u001B[0m, in \u001B[0;36mimopen\u001B[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m     request\u001B[38;5;241m.\u001B[39mformat_hint \u001B[38;5;241m=\u001B[39m format_hint\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 113\u001B[0m     request \u001B[38;5;241m=\u001B[39m Request(uri, io_mode, format_hint\u001B[38;5;241m=\u001B[39mformat_hint, extension\u001B[38;5;241m=\u001B[39mextension)\n\u001B[1;32m    115\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<bytes>\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(uri, \u001B[38;5;28mbytes\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m uri\n\u001B[1;32m    117\u001B[0m \u001B[38;5;66;03m# fast-path based on plugin\u001B[39;00m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;66;03m# (except in legacy mode)\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/imageio/core/request.py:247\u001B[0m, in \u001B[0;36mRequest.__init__\u001B[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001B[0m\n\u001B[1;32m    244\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Request.Mode: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    246\u001B[0m \u001B[38;5;66;03m# Parse what was given\u001B[39;00m\n\u001B[0;32m--> 247\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_uri(uri)\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# Set extension\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extension \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/imageio/core/request.py:407\u001B[0m, in \u001B[0;36mRequest._parse_uri\u001B[0;34m(self, uri)\u001B[0m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_read_request:\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;66;03m# Reading: check that the file exists (but is allowed a dir)\u001B[39;00m\n\u001B[1;32m    406\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(fn):\n\u001B[0;32m--> 407\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo such file: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m fn)\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    409\u001B[0m     \u001B[38;5;66;03m# Writing: check that the directory to write to does exist\u001B[39;00m\n\u001B[1;32m    410\u001B[0m     dn \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(fn)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: No such file: '/home/jakubbaransky/DataspellProjects/compVisionZS/example files/jaguar.gif'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy, contrast, correlation, energy, homogeneity\n",
    "\n",
    "Based on subjective impression, we could say that there are three basic textures in the image, the texture of the jaguar, the background leaves and the tree trunk. In order to segment the image algorithmically, we need to find quantifiable properties that would describe these textures. We will first consider small sections of the original image. One of the attributes describing textures is entropy, which reflects the degree of randomness in the texture. We calculate the entropy for each pixel based on its brightness and the brightness of the pixels around it using the entropy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T12:04:58.144912Z",
     "start_time": "2023-10-15T12:04:57.768355Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (9, 9))\n",
    "plt.title('Entropy')\n",
    "im_entropy = entropy(img, morphology.disk(5))\n",
    "plt.imshow(im_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the image that the entropy distinguishes the jaguar texture from the rest of the image quite well. However, there are many other texture attributes. We will now calculate some of them for the same neighborhood as above, namely:\n",
    "\n",
    "- **Contrast**, the difference between the brightness intensities of a pixel and its neighbors in the entire viewport. Contrast is zero for a constant image.\n",
    "- **Correlation**, a statistical measure of the dependence of the brightness value of a pixel on the brightness values of its neighbors.\n",
    "- **Energy** determines the degree of orderliness of the image.\n",
    "- **Homogeneity**, a quality determining the degree of similarity of different image areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spacing of examined pixels, if not defined otherwise, is 0 rows and 1 column, i.e. the scaled brightness values of neighboring pixels in the horizontal direction are examined. We initialize these zero matrices with the dimension of the im_entropy array.\n",
    "\n",
    "Now we will cycle through all the slices of the image. For each section, we calculate the co-occurrence matrix and the values of the monitored properties. We write these into the corresponding matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a window from the grayscale image, where the size of the window is defined by window_size.\n",
    "# Calculate the Gray-Level Co-occurrence Matrix (GLCM) for the window using greycomatrix from scikit-image.\n",
    "# Calculate the specified texture properties (contrast, correlation, energy, homogeneity) from the GLCM using greycoprops.\n",
    "# Store the calculated texture properties in the corresponding matrices (im_contrast, im_correlation, im_energy, im_homogeneity) at the appropriate location.\n",
    "# The resulting matrices now contain the texture properties for different sections of the image, which you can use for further analysis or visualization.\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "# Ignore DeprecationWarning\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, module='skimage')\n",
    "\n",
    "# Define the parameters for texture analysis\n",
    "distances = [1]\n",
    "angles = [0]\n",
    "properties = ['contrast', 'correlation', 'energy', 'homogeneity']\n",
    "window_size = 9\n",
    "\n",
    "# Initialize matrices to store texture properties\n",
    "im_contrast = np.zeros_like(im_entropy)\n",
    "im_correlation = np.zeros_like(im_entropy)\n",
    "im_energy = np.zeros_like(im_entropy)\n",
    "im_homogeneity = np.zeros_like(im_entropy)\n",
    "\n",
    "# Iterate through image slices to calculate texture properties\n",
    "for i in tqdm(range(0, im_entropy.shape[0] - window_size)):\n",
    "    for j in range(0, im_entropy.shape[1] - window_size):\n",
    "\n",
    "        # Extract a window from the grayscale image\n",
    "        window = img[i:i + window_size, j:j + window_size]\n",
    "\n",
    "        # Calculate the gray-level co-occurrence matrix (GLCM) for the window\n",
    "        glcm = greycomatrix(window,\n",
    "                            distances=distances,\n",
    "                            angles=angles,\n",
    "                            symmetric=True,\n",
    "                            normed=True)\n",
    "\n",
    "        # Calculate and store texture properties in the corresponding matrices\n",
    "        feats = np.hstack([greycoprops(glcm, prop).ravel() for prop in properties])\n",
    "        im_contrast[i, j] = feats[0]\n",
    "        im_correlation[i, j] = feats[1]\n",
    "        im_energy[i, j] = feats[2]\n",
    "        im_homogeneity[i, j] = feats[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T12:05:54.550678Z",
     "start_time": "2023-10-15T12:05:53.723649Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(221)\n",
    "plt.title('Contrast')\n",
    "plt.imshow(im_contrast)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('Correlation')\n",
    "plt.imshow(im_correlation)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title('Energy')\n",
    "plt.imshow(im_energy)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.title('Homogeneity')\n",
    "plt.imshow(im_homogeneity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By visual analysis of the images, we can conclude that:\n",
    "\n",
    "Energy is low in the jaguar texture and medium to high in the rest of the image.\n",
    "Entropy is significantly negatively correlated with energy.\n",
    "Contrast is high in the jaguar texture and low in the rest of the image.\n",
    "Thus, it should be relatively easy to segment the jaguar texture based on information about the contrast and energy of the viewed section. Therefore, in the following code we will focus on contrast and energy. We smooth the output with a median filter for noise suppression and convert their values to the <0, 1> interval.\n",
    "\n",
    "A scatterplot is a useful tool when studying the dependence of two or three variables. Now we construct a diagram where we plot the energy value on the X axis and the contrast value on the Y axis. Each pair of energy and contrast values corresponding to a pixel appears in the graph as a blue dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T12:05:54.680921Z",
     "start_time": "2023-10-15T12:05:54.549372Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10, 10))\n",
    "plt.title('Plot of dispersion')\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Contrast')\n",
    "plt.scatter(im_energy.ravel(), im_contrast.ravel(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture segmentation by thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the scatter diagram, we can observe basically three types of points:\n",
    "\n",
    "- Points with lower energy and higher contrast.\n",
    "- Points with lower contrast and energy.\n",
    "- Points with lower contrast and higher energy.\n",
    "\n",
    "From the images above, we concluded that the jaguar texture is characterized by higher contrast and lower energy. We segment pixels that match the following criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T12:05:54.691638Z",
     "start_time": "2023-10-15T12:05:54.609862Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10, 10))\n",
    "plt.title('Thresholding texture segmentation')\n",
    "plt.imshow(np.logical_and(im_energy < 0.15, im_contrast > 1200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autonomous task 1\n",
    "\n",
    "Improve the quality of segmentation by thresholding on the image of a jaguar e.g. by applying Gaussian blur, changing the way attributes are calculated, or in any other way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture segmentation by clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to segment the jaguar based on its specific texture. In general, however, we describe the texture with several attributes - symptoms. It would be convenient to automatically segment the image into areas with different textures. For this purpose we will now use a simple method for clustering. The goal of clustering is to divide the feature space into regions where samples with similar properties are found. We implement a simple proprietary algorithm based on the principle \"winner takes all\" (Winner Takes All, WTA). First, we define the set of samples and the parameters of the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T12:06:30.381100Z",
     "start_time": "2023-10-15T12:06:26.270842Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new variables for normalized energy and contrast\n",
    "normalized_energy = im_energy / np.max(im_energy)\n",
    "normalized_contrast = im_contrast / np.max(im_contrast)\n",
    "\n",
    "# Create feature vectors for clustering\n",
    "energy = np.expand_dims(normalized_energy, axis=2)\n",
    "contrast = np.expand_dims(normalized_contrast, axis=2)\n",
    "X = np.concatenate((energy, contrast), axis=2)\n",
    "\n",
    "# Define clustering parameters\n",
    "n_iter = 5\n",
    "n_centers = 2\n",
    "alfa = 0.07\n",
    "\n",
    "# Initialize random cluster centers\n",
    "centers = np.random.rand(n_centers, X.shape[2])\n",
    "\n",
    "# Perform clustering using the Winner Takes All (WTA) algorithm\n",
    "for i in range(n_iter):\n",
    "    for x in np.random.permutation(X.shape[0]):\n",
    "        for y in np.random.permutation(X.shape[1]):\n",
    "            item = X[x, y]\n",
    "            distances = centers - np.tile(item, (n_centers, 1))\n",
    "            distances = np.sum((distances ** 2), axis=1)\n",
    "            min_distance = np.min(distances)\n",
    "            indx = np.where(distances == min_distance)\n",
    "            centers[indx] = (item - centers[indx]) * alfa + centers[indx]\n",
    "\n",
    "# Create the segmentation output based on cluster indices\n",
    "output = np.zeros(im_contrast.shape)\n",
    "for x in range(X.shape[0]):\n",
    "    for y in range(X.shape[1]):\n",
    "        item = X[x, y]\n",
    "        distances = centers - np.tile(item, (n_centers, 1))\n",
    "        distances = np.sum((distances ** 2), axis=1)\n",
    "        min_distance = np.min(distances)\n",
    "        indx = np.where(distances == min_distance)\n",
    "        output[x, y] = indx[0]\n",
    "\n",
    "# Visualize the segmented image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Texture Segmentation by Clustering')\n",
    "RGB_label = label2rgb(output)\n",
    "plt.imshow(RGB_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T12:06:30.489199Z",
     "start_time": "2023-10-15T12:06:30.383012Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10, 10))\n",
    "plt.title('Texture mask applied to the original image')\n",
    "\n",
    "# explain later :)\n",
    "# chnl = RGB_label[:, :, 2]\n",
    "# out = filters.threshold_otsu(chnl)\n",
    "# mask = chnl < out\n",
    "# finalMask = morphology.remove_small_holes(morphology.dilation(morphology.opening(RGB_label[:,:,1], morphology.disk(2)), morphology.disk(1)), 256)\n",
    "# finalMask = morphology.remove_small_objects(finalMask, min_size= 100)\n",
    "\n",
    "jaguar = img * RGB_label[:, :, 0]\n",
    "plt.imshow(jaguar, cmap= 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T12:06:30.618438Z",
     "start_time": "2023-10-15T12:06:30.499345Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10, 10))\n",
    "plt.title(\"Texture boundaries\")\n",
    "boundary = find_boundaries(jaguar)\n",
    "M_boundary = mark_boundaries(img, boundary, color= (1, 0, 0))\n",
    "plt.imshow(M_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autonomous work 2\n",
    "\n",
    "Change the texture segmentation by clustering so that the input vector of features can have an arbitrary length. Select the most suitable features (e.g. by calculating the co-occurrence matrix with different displacement vectors, different tile sizes, lowering the number of gray levels in the input image, etc.) so that you arrive at three textures when segmenting the image using clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
